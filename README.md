# EN.605.611 - Introduction to Machine Learning
### Author: Daniel Nashed

## Package Description
This package is an end-to-end machine learing pipeline to be used to develop, train and run inference of machine learning models.

## Package File Structure

ðŸ“¦Machine Learning Pipeline<br>
 â”ƒ <br>
 â”£ ðŸ“‚datasets<br>
 â”ƒ â”ƒ <br>
 â”ƒ â”£ ðŸ“‚Classification Data Sets<br>
 â”ƒ â”ƒ â”ƒ <br>
 â”ƒ â”ƒ â”£ ðŸ“‚Breast Cancer<br>
 â”ƒ â”ƒ â”ƒ â”£ breast-cancer-wisconsin.config --> structured INI file for processing dataset<br> 
 â”ƒ â”ƒ â”ƒ â”£ breast-cancer-wisconsin.names --> unstructured txt file with dataset description<br>
 â”ƒ â”ƒ â”ƒ â”— breast-cancer-wisconsin.data --> txt file containing data<br>
 â”ƒ â”ƒ â”ƒ <br>
 â”ƒ â”ƒ â”£ ðŸ“‚Car Evaluation<br>
 â”ƒ â”ƒ â”ƒ â”£ car.config --> structured INI file for processing dataset<br> 
 â”ƒ â”ƒ â”ƒ â”£ car.names --> unstructured txt file with dataset description<br>
 â”ƒ â”ƒ â”ƒ â”— car.data --> txt file containing data<br>
 â”ƒ â”ƒ â”ƒ <br>
 â”ƒ â”ƒ â”— ðŸ“‚Congressional Vote<br>
 â”ƒ â”ƒ â”ƒ â”£ house-votes-84.config --> structured INI file for processing dataset<br> 
 â”ƒ â”ƒ â”ƒ â”£ house-votes-84.names --> unstructured txt file with dataset description<br>
 â”ƒ â”ƒ â”ƒ â”— house-votes-84.data --> txt file containing data<br>
 â”ƒ â”ƒ <br>
 â”ƒ â”£ ðŸ“‚Regression Data Sets<br>
 â”ƒ â”ƒ â”ƒ <br>
 â”ƒ â”ƒ â”£ ðŸ“‚Abalone<br>
 â”ƒ â”ƒ â”ƒ â”£ abalone.config  --> structured INI file for processing dataset<br>
 â”ƒ â”ƒ â”ƒ â”£ abalone.names --> unstructured txt file with dataset description<br>
 â”ƒ â”ƒ â”ƒ â”— abalone.data --> txt file containing data<br>
 â”ƒ â”ƒ â”ƒ <br>
 â”ƒ â”ƒ â”£ ðŸ“‚Computer Hardware<br>
 â”ƒ â”ƒ â”ƒ â”£ machine.config --> structured INI file for processing dataset<br> 
 â”ƒ â”ƒ â”ƒ â”£ machine.names --> unstructured txt file with dataset description<br>
 â”ƒ â”ƒ â”ƒ â”— machine.data --> txt file containing data<br>
 â”ƒ â”ƒ â”ƒ <br>
 â”ƒ â”ƒ â”— ðŸ“‚Forest Fires<br>
 â”ƒ â”ƒ â”ƒ â”£ forestfires.config --> structured INI file for processing dataset<br> 
 â”ƒ â”ƒ â”ƒ â”£ forestfires.names --> unstructured txt file with dataset description<br>
 â”ƒ â”ƒ â”ƒ â”— forestfires.data --> txt file containing data<br>
 â”ƒ â”ƒ â”ƒ <br>
 â”ƒ â”£ ðŸ“‚Reinforcement Learning Data Sets<br>
 â”ƒ â”ƒ â”ƒ <br>
 â”ƒ â”ƒ â”— ðŸ“‚Racetracks<br>
 â”ƒ â”ƒ â”ƒ â”£ L-track.txt --> txt file containing data<br>
 â”ƒ â”ƒ â”ƒ â”£ O-track.txt --> txt file containing data<br>
 â”ƒ â”ƒ â”ƒ â”£ R-track.txt --> txt file containing data<br>
 â”ƒ â”ƒ â”ƒ â”— W-track.txt --> txt file containing data<br>
 â”ƒ â”ƒ <br>
 â”ƒ â”— template.config<br>
 â”ƒ<br>
 â”£ ðŸ“‚feature_pipeline<br>
 â”ƒ â”— data_transformer.py --> class with methods for pre-processing of dataset<br>
 â”ƒ <br>
 â”£ ðŸ“‚training_pipeline<br>
 â”ƒ â”£ learner.py --> class with methods to train an ml model<br>
 â”ƒ â”£ evaluator.py --> class with methods to evaluate model performance<br>
 â”ƒ â”— dashboard.py --> class with methods to display evaluation metrics<br>
 â”ƒ <br>
 â”£ ðŸ“‚inference_pipeline <br>
 â”ƒ â”ƒ <br>
 â”ƒ â”£ model.py --> abstract class interface to represent an ml model<br>
 â”ƒ â”ƒ <br>
 â”ƒ â”£ ðŸ“‚null_model --> baseline model using mean or mode of target class<br>
 â”ƒ â”ƒ â”£ null_model.py --> class and methods to model a null model<br>
 â”ƒ â”ƒ â”— null_model.config --> structured INI file to configure model<br>
 â”ƒ â”ƒ <br>
 â”ƒ â”£ ðŸ“‚knn --> k-nearest neighbour model<br>
 â”ƒ â”ƒ â”£ knn.py --> class and methods to model a knn model<br>
 â”ƒ â”ƒ â”— knn.config --> structured INI file to configure model<br>
 â”ƒ â”ƒ <br>
 â”ƒ â”£ ðŸ“‚edited_knn --> edited k-nearest neighbour model to improve inference time<br>
 â”ƒ â”ƒ â”£ edited_knn.py --> class and methods to model a knn model<br>
 â”ƒ â”ƒ â”— edited_knn.config --> structured INI file to configure model<<br>
 â”ƒ <br>
 â”£ ðŸ“‚output --> directory to hold outputs of pipelines<br>
 â”ƒ â”ƒ <br>
 â”ƒ â”£ run.py --> entry point for package pipeline<br>
 â”ƒ â”— README.md<br>
 â”ƒ<br>

## Installation & Running Instructions
### Cloning the Package
Clone the root directory named "Machine Learning Pipeline"

### Python
The project has been written using Python 3.12.1

### Package Requirements
All dependencies required for the project have been listed in the file `requirements.txt`. Use the following command to install all dependencies at once: 
`pip3 install -r requirements.txt` 

### Running the Package
The entry point is provided in run.py located in the root directory. To run a pipeline, modify the config dictionary inside the main method as follows:

- 'model': choose from 'null_model', 'knn', 'edited_knn'
- 'dataset': choose from 'car', 'breast-cancer-wisconsin' 'house-votes-84', 'abalone',  'machine', 'forestfires', 'racetracks'
- 'mode': choose from 'training', 'inference'
- 'cross_validation_splits': number of experiments 'k' to run k x 2 cross validation

### Modifying Config Files
Each model and each datset has its own structured INI config file that contains configuturable parameters which can be modified by users. 

For example, for datasets, the choice of what missing values to impute or ignore, whether a categorical feature is ordinal or nominal, what type of transformation to apply (standardization or normalization), which class label is the positive class, and so on can all be specified within the respective config file of each dataset. 

For models, all hyperparameters can specified in their respective config files as well as a key-value pair where the key is the name of the hyperparameter and the value is a list of values for the hyperparameter. If no hypertuning is required, then the value is simply a list of size 1. The type of prediction to perform, either regression, binary-classification or multi-classification can also be specified. In addition, the choice of which metrics to use for evaluation can be specified in the config file. If multiple metrics are needed for evaluation, simply set the value of the respective metric key to 1. Otherwise, keep value at 0 if you do not wish to use the metric for evaluation.


### Outputs
Each time a pipeline is executed, a new subdirectory is created inside 'outputs' directory to hold all exported data pertaining to an executed pipeline. The following files are exported during pipeline execution:

- pickle file containing the trained model 
- pickle file containing logs for the model during hyperparameter tuning & training
- csv file containing processed train dataset prior to transformation and k-fold splits
- csv file containing processed validation dataset prior to transformation and k-fold splits
- png image for learning curves of the model during training 
- png image for validation curves of the model during training